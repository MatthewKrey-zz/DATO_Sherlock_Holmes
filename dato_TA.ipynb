{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'link': '/stories/plain-text/cano.txt', 'title': 'The Complete Canon'}, {'link': '/stories/plain-text/cnus.txt', 'title': 'The Canon \\xe2\\x80\\x94 U.S. edition'}, {'link': '/stories/plain-text/advs.txt', 'title': 'The Adventures of Sherlock Holmes'}, {'link': '/stories/plain-text/mems.txt', 'title': 'The Memoirs of Sherlock Holmes'}, {'link': '/stories/plain-text/retn.txt', 'title': 'The Return of Sherlock Holmes'}, {'link': '/stories/plain-text/lstb.txt', 'title': 'His Last Bow'}, {'link': '/stories/plain-text/case.txt', 'title': 'The Case-Book of Sherlock Holmes'}, {'link': '/stories/plain-text/stud.txt', 'title': 'A Study In Scarlet'}, {'link': '/stories/plain-text/sign.txt', 'title': 'The Sign of the Four'}, {'link': '/stories/plain-text/houn.txt', 'title': 'The Hound of the Baskervilles'}, {'link': '/stories/plain-text/vall.txt', 'title': 'The Valley of Fear'}, {'link': '/stories/plain-text/scan.txt', 'title': 'A Scandal in Bohemia'}, {'link': '/stories/plain-text/redh.txt', 'title': 'The Red-Headed League'}, {'link': '/stories/plain-text/iden.txt', 'title': 'A Case of Identity'}, {'link': '/stories/plain-text/bosc.txt', 'title': 'The Boscombe Valley Mystery'}, {'link': '/stories/plain-text/five.txt', 'title': 'The Five Orange Pips'}, {'link': '/stories/plain-text/twis.txt', 'title': 'The Man with the Twisted Lip'}, {'link': '/stories/plain-text/blue.txt', 'title': 'The Adventure of the Blue Carbuncle'}, {'link': '/stories/plain-text/spec.txt', 'title': 'The Adventure of the Speckled Band'}, {'link': '/stories/plain-text/engr.txt', 'title': \"The Adventure of the Engineer's Thumb\"}, {'link': '/stories/plain-text/nobl.txt', 'title': 'The Adventure of the Noble Bachelor'}, {'link': '/stories/plain-text/bery.txt', 'title': 'The Adventure of the Beryl Coronet'}, {'link': '/stories/plain-text/copp.txt', 'title': 'The Adventure of the Copper Beeches'}, {'link': '/stories/plain-text/silv.txt', 'title': 'Silver Blaze'}, {'link': '/stories/plain-text/yell.txt', 'title': 'Yellow Face'}, {'link': '/stories/plain-text/stoc.txt', 'title': \"The Stockbroker's Clerk\"}, {'link': '/stories/plain-text/glor.txt', 'title': 'The \\xe2\\x80\\x9cGloria Scott\\xe2\\x80\\x9d'}, {'link': '/stories/plain-text/musg.txt', 'title': 'The Musgrave Ritual'}, {'link': '/stories/plain-text/reig.txt', 'title': 'The Reigate Puzzle'}, {'link': '/stories/plain-text/croo.txt', 'title': 'The Crooked Man'}, {'link': '/stories/plain-text/resi.txt', 'title': 'The Resident Patient'}, {'link': '/stories/plain-text/gree.txt', 'title': 'The Greek Interpreter'}, {'link': '/stories/plain-text/nava.txt', 'title': 'The Naval Treaty'}, {'link': '/stories/plain-text/fina.txt', 'title': 'The Final Problem'}, {'link': '/stories/plain-text/empt.txt', 'title': 'The Empty House'}, {'link': '/stories/plain-text/norw.txt', 'title': 'The Norwood Builder'}, {'link': '/stories/plain-text/danc.txt', 'title': 'The Dancing Men'}, {'link': '/stories/plain-text/soli.txt', 'title': 'The Solitary Cyclist'}, {'link': '/stories/plain-text/prio.txt', 'title': 'The Priory School'}, {'link': '/stories/plain-text/blac.txt', 'title': 'Black Peter'}, {'link': '/stories/plain-text/chas.txt', 'title': 'Charles Augustus Milverton'}, {'link': '/stories/plain-text/sixn.txt', 'title': 'The Six Napoleons'}, {'link': '/stories/plain-text/3stu.txt', 'title': 'The Three Students'}, {'link': '/stories/plain-text/gold.txt', 'title': 'The Golden Pince-Nez'}, {'link': '/stories/plain-text/miss.txt', 'title': 'The Missing Three-Quarter'}, {'link': '/stories/plain-text/abbe.txt', 'title': 'The Abbey Grange'}, {'link': '/stories/plain-text/seco.txt', 'title': 'The Second Stain'}, {'link': '/stories/plain-text/wist.txt', 'title': 'Wisteria Lodge'}, {'link': '/stories/plain-text/card.txt', 'title': 'The Cardboard Box'}, {'link': '/stories/plain-text/redc.txt', 'title': 'The Red Circle'}, {'link': '/stories/plain-text/bruc.txt', 'title': 'The Bruce-Partington Plans'}, {'link': '/stories/plain-text/dyin.txt', 'title': 'The Dying Detective'}, {'link': '/stories/plain-text/lady.txt', 'title': 'Lady Frances Carfax'}, {'link': '/stories/plain-text/devi.txt', 'title': \"The Devil's Foot\"}, {'link': '/stories/plain-text/last.txt', 'title': 'His Last Bow'}, {'link': '/stories/plain-text/illu.txt', 'title': 'The Illustrious Client'}, {'link': '/stories/plain-text/blan.txt', 'title': 'The Blanched Soldier'}, {'link': '/stories/plain-text/maza.txt', 'title': 'The Mazarin Stone'}, {'link': '/stories/plain-text/3gab.txt', 'title': 'The Three Gables'}, {'link': '/stories/plain-text/suss.txt', 'title': 'The Sussex Vampire'}, {'link': '/stories/plain-text/3gar.txt', 'title': 'The Three Garridebs'}, {'link': '/stories/plain-text/thor.txt', 'title': 'Thor Bridge'}, {'link': '/stories/plain-text/cree.txt', 'title': 'The Creeping Man'}, {'link': '/stories/plain-text/lion.txt', 'title': \"The Lion's Mane\"}, {'link': '/stories/plain-text/veil.txt', 'title': 'The Veiled Lodger'}, {'link': '/stories/plain-text/shos.txt', 'title': 'Shoscombe Old Place'}, {'link': '/stories/plain-text/reti.txt', 'title': 'The Retired Colourman'}]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import urllib2 \n",
    "import graphlab as gl\n",
    "\n",
    "BASE_DIR = \"/Users/matthewkrey/anaconda2/DATO/sherlock\" # match BASE_DIR to your local directory path\n",
    "\n",
    "books_url = \"http://sherlock-holm.es/ascii/\"\n",
    "re_books_links = re.compile(\"\\\"piwik_download\\\"\\s+href=\\\"(?P<link>.*?)\\\">(?P<title>.*?)</a>\", re.MULTILINE)\n",
    "html = urllib2.urlopen(books_url).read()\n",
    "books_list = [m.groupdict() for m in re_books_links.finditer(html)]\n",
    "print books_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter books due to copyright issues. In this code, we filtered \"The Complete Canon\", “Case-Book of Sherlock Holmes” books, and\n",
    "# \"The Canon — U.S. edition\" book (For more information please read the note above).\n",
    "\n",
    "filtered_books = set([\"The Complete Canon\", \"The Case-Book of Sherlock Holmes\", \"The Canon - U.S. edition\" ])\n",
    "books_list = filter(lambda d: d['title'] not in filtered_books, books_list)\n",
    "\n",
    "# Download books' texts (to not overload the website we download the text in batch and not in parallel)\n",
    "for d in books_list:\n",
    "    d['text'] = urllib2.urlopen(\"http://sherlock-holm.es\" + d['link']).read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to matthew.krey@flatironschool.com and will expire on December 14, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-43356 - Server binary: /Users/matthewkrey/anaconda2/envs/dato-env/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1452983201.log\n",
      "[INFO] GraphLab Server Version: 1.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">link</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">/stories/plain-<br>text/cnus.txt ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">THE COMPLETE SHERLOCK<br>HOLMES\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The Canon — U.S.<br>edition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">/stories/plain-<br>text/advs.txt ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">THE ADVENTURES OF<br>SHERLOCK HOLMES\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The Adventures of<br>Sherlock Holmes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">/stories/plain-<br>text/mems.txt ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">THE MEMOIRS OF SHERLOCK<br>HOLMES\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The Memoirs of Sherlock<br>Holmes ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tlink\tstr\n",
       "\ttext\tstr\n",
       "\ttitle\tstr\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+------------------------------+-------------------------------+\n",
       "|             link             |              text             |\n",
       "+------------------------------+-------------------------------+\n",
       "| /stories/plain-text/cnus.txt | THE COMPLETE SHERLOCK HOLM... |\n",
       "| /stories/plain-text/advs.txt | THE ADVENTURES OF SHERLOCK... |\n",
       "| /stories/plain-text/mems.txt | THE MEMOIRS OF SHERLOCK HO... |\n",
       "+------------------------------+-------------------------------+\n",
       "+--------------------------------+\n",
       "|             title              |\n",
       "+--------------------------------+\n",
       "|    The Canon — U.S. edition    |\n",
       "| The Adventures of Sherlock...  |\n",
       "| The Memoirs of Sherlock Holmes |\n",
       "+--------------------------------+\n",
       "[3 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load list of dictionaries containing text of interest into SFrame\n",
    "\n",
    "sf = gl.SFrame(books_list).unpack(\"X1\", column_name_prefix=\"\")\n",
    "sf.save(\"%s/books.sframe\" % BASE_DIR)\n",
    "sf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:57261/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "# With SFrame now \"loaded\", we can leverage Python stdlib for stats & visualizations\n",
    "\n",
    "# stats \n",
    "sf['chars_num'] = sf['text'].apply(lambda t: len(t))\n",
    "sf.head(3)\n",
    "\n",
    "# visualization \n",
    "sf['chars_num'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Using .split() method\n",
      "##########\n",
      "['I', 'think', 'that', 'you', 'know', 'me', 'well', 'enough,', 'Watson,', 'to', 'understand', 'that', 'I', 'am', 'by', 'no', 'means', 'a', 'nervous', 'man.', 'At', 'the', 'same', 'time,', 'it', 'is', 'stupidity', 'rather', 'than', 'courage', 'to', 'refuse', 'to', 'recognize', 'danger', 'when', 'it', 'is', 'close', 'upon', 'you.']\n",
      "##########\n",
      "41\n",
      "##########\n",
      "##########\n",
      "Using Regular Expressions\n",
      "##########\n",
      "['I', 'think', 'that', 'you', 'know', 'me', 'well', 'enough', 'Watson', 'to', 'understand', 'that', 'I', 'am', 'by', 'no', 'means', 'a', 'nervous', 'man', 'At', 'the', 'same', 'time', 'it', 'is', 'stupidity', 'rather', 'than', 'courage', 'to', 'refuse', 'to', 'recognize', 'danger', 'when', 'it', 'is', 'close', 'upon', 'you']\n",
      "##########\n",
      "41\n",
      "##########\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matthewkrey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "##########\n",
      "Using NLTK\n",
      "##########\n",
      "['I', 'think', 'that', 'you', 'know', 'me', 'well', 'enough', ',', 'Watson', ',', 'to', 'understand', 'that', 'I', 'am', 'by', 'no', 'means', 'a', 'nervous', 'man', '.', 'At', 'the', 'same', 'time', ',', 'it', 'is', 'stupidity', 'rather', 'than', 'courage', 'to', 'refuse', 'to', 'recognize', 'danger', 'when', 'it', 'is', 'close', 'upon', 'you', '.']\n",
      "##########\n",
      "46\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "# Calculating number of words in a text. Various approaches.\n",
    "# Note differences in how each approach splits words & punctuation! \n",
    "\n",
    "text = \"\"\"I think that you know me well enough, Watson, to understand that I am by no means a nervous man. At the same time,\n",
    "it is stupidity rather than courage to refuse to recognize danger when it is close upon you.\"\"\"\n",
    "\n",
    "# Using .split()\n",
    "\n",
    "print \"##########\"\n",
    "print \"Using .split() method\"\n",
    "print \"##########\"\n",
    "print text.split()\n",
    "print \"##########\"\n",
    "print len(text.split())\n",
    "print \"##########\"\n",
    "\n",
    "# Using regular expressions\n",
    "\n",
    "re_words_split = re.compile(\"(\\w+)\")\n",
    "\n",
    "print \"##########\"\n",
    "print \"Using Regular Expressions\"\n",
    "print \"##########\"\n",
    "print re_words_split.findall(text)\n",
    "print \"##########\"\n",
    "print len(re_words_split.findall(text))\n",
    "print \"##########\"\n",
    "\n",
    "# Using Natural Language Toolkit (NLTK)\n",
    "# Note from DATO: Remember to download the NLTK's punkt package by running nltk.download() from the Interactive Python Shell\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "print \"##########\"\n",
    "print \"Using NLTK\"\n",
    "print \"##########\"\n",
    "print nltk.word_tokenize(text)\n",
    "print \"##########\"\n",
    "print len(nltk.word_tokenize(text))\n",
    "print \"##########\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count number of words using regex approach \n",
    "\n",
    "sf['words_num'] = sf['text'].apply(lambda t: len(re_words_split.findall(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "# Count number of sentences using NLTK\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def txt2sentences(txt, remove_none_english_chars=True):\n",
    "    \"\"\"\n",
    "    Split the English text into sentences using NLTK\n",
    "    :param txt: input text.\n",
    "    :param remove_none_english_chars: if True then remove none English chars from text\n",
    "    :return: string in which each line consists of single sentence from the original input text.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # decode to utf8 to avoid encoding problems \n",
    "    txt = txt.decode(\"utf8\")\n",
    "    # split text into sentences using NLTK package\n",
    "    for s in tokenizer.tokenize(txt):\n",
    "        if remove_none_english_chars:\n",
    "            # remove none English chars\n",
    "            s = re.sub(\"[^a-zA-Z]\", \" \", s)\n",
    "            yield s \n",
    "\n",
    "# count number of sentences\n",
    "sf['sentences_num'] = sf['text'].apply(lambda t: len(list(txt2sentences(t))))\n",
    "\n",
    "# visualize \n",
    "sf[['chars_num','words_num','sentences_num']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "# More advanced text analysis with GraphLab's text_analytics.count_words toolkit and collection.Counter function\n",
    "\n",
    "sf['words_count'] = gl.text_analytics.count_words(sf['text'], to_lower=True)\n",
    "sf['sherlock_count'] = sf['words_count'].apply(lambda d: d.get('sherlock',0))\n",
    "sf['watson_count'] = sf['words_count'].apply(lambda d: d.get('watson',0))\n",
    "sf['elementary_count'] = sf['words_count'].apply(lambda d: d.get('elementary',0))\n",
    "sf[['sherlock_count', 'watson_count', 'elementary_count']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 65\n",
      "PROGRESS: Number of features          : 1\n",
      "PROGRESS: Number of unpacked features : 1\n",
      "PROGRESS: Number of coefficients    : 2\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 2        | 1.008692     | 75.095997          | 20.931039     |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: SUCCESS: Optimal solution found.\n",
      "PROGRESS:\n",
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to use Linear Regression to predict the number of times the word 'Sherlock' appears in a text based on the number of times the word 'Watson' appears in the text.\n",
    "\n",
    "linear_reg = gl.linear_regression.create(sf, target='sherlock_count', features=['watson_count'])\n",
    "linear_reg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
